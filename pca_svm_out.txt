dftrain shape head (7352, 562) 
          x0        x1        x2        x3        x4        x5        x6  \
0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   
1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   
2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   

         x7        x8        x9   ...         x552      x553      x554  \
0 -0.983185 -0.923527 -0.934724   ...    -0.298676 -0.710304 -0.112754   
1 -0.974914 -0.957686 -0.943068   ...    -0.595051 -0.861499  0.053477   
2 -0.963668 -0.977469 -0.938692   ...    -0.390748 -0.760104 -0.118559   

       x555      x556      x557      x558      x559      x560  subject  
0  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627        1  
1 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317        1  
2  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118        1  

[3 rows x 562 columns]
dftest shape head (2947, 562) 
          x0        x1        x2        x3        x4        x5        x6  \
0  0.257178 -0.023285 -0.014654 -0.938404 -0.920091 -0.667683 -0.952501   
1  0.286027 -0.013163 -0.119083 -0.975415 -0.967458 -0.944958 -0.986799   
2  0.275485 -0.026050 -0.118152 -0.993819 -0.969926 -0.962748 -0.994403   

         x7        x8        x9   ...         x552      x553      x554  \
0 -0.925249 -0.674302 -0.894088   ...    -0.330370 -0.705974  0.006462   
1 -0.968401 -0.945823 -0.894088   ...    -0.121845 -0.594944 -0.083495   
2 -0.970735 -0.963483 -0.939260   ...    -0.190422 -0.640736 -0.034956   

       x555      x556      x557      x558      x559      x560  subject  
0  0.162920 -0.825886  0.271151 -0.720009  0.276801 -0.057978        2  
1  0.017500 -0.434375  0.920593 -0.698091  0.281343 -0.083898        2  
2  0.202302  0.064103  0.145068 -0.702771  0.280083 -0.079346        2  

[3 rows x 562 columns]
do_pca all : keylen 562
  pfit shape (7352, 562)
[[  1.57272239e+01   7.24625881e+00  -4.65589364e-01 ...,  -6.91888142e-17
   -1.75222535e-17  -3.04372143e-16]
 [  1.57233170e+01   7.26069038e+00  -2.59002156e-01 ...,   7.64289089e-17
    1.09172497e-16   4.69710903e-18]
 [  1.57425696e+01   7.20400561e+00   1.06483367e-01 ...,   1.07479487e-16
   -3.39254542e-16  -2.41983084e-16]]
  PCA comp norm? True
  Orig comp norm? True
  fit is near equal to dot product? False
  comps shape (562, 562)
[[ -1.89038192e-04   5.63432576e-07  -6.74636814e-06 ...,   1.55136272e-03
    4.05384703e-03  -9.93804085e-01]
 [  2.52767847e-05   3.06535950e-04   2.34616140e-04 ...,  -2.70090701e-02
   -2.15126567e-02  -1.06982334e-01]
 [  3.30402666e-03  -4.40063962e-04  -8.47244651e-04 ...,  -3.87329061e-02
   -1.50488900e-02   9.47209889e-03]
 ..., 
 [  0.00000000e+00  -5.14926282e-16  -2.95103769e-17 ...,   1.53523465e-16
    1.81013307e-16   3.41922531e-19]
 [  0.00000000e+00  -4.19186250e-16   2.14827708e-17 ...,  -1.89788273e-16
    5.91142595e-17  -2.03770951e-18]
 [  0.00000000e+00  -6.84680929e-17  -3.06740429e-17 ...,   8.10096660e-17
    8.71746994e-18  -1.60700773e-18]]
  explained_variance_ratio: [ 0.59581138  0.2516909   0.02002546] ... [  7.35096875e-36   1.62446413e-36   3.27087546e-37] : sum = 1.0
  vartotal ['60%', '85%', '87%', '88%', '89%', '90%', '90%', '91%', '91%', '92%', '92%', '92%', '93%', '93%', '93%', '93%', '94%', '94%', '94%', '94%', '94%', '94%', '95%', '95%', '95%', '95%', '95%', '95%', '95%', '95%', '96%', '96%', '96%', '96%', '96%']
  explained_variance_ratio: [ 0.59581138  0.2516909   0.02002546] ... [ 0.0002195   0.0002152   0.00021367] : sum = 0.98877462042
  vartotal ['60%', '85%', '87%', '88%', '89%', '90%', '90%', '91%', '91%', '92%', '92%', '92%', '93%', '93%', '93%', '93%', '94%', '94%', '94%', '94%', '94%', '94%', '95%', '95%', '95%', '95%', '95%', '95%', '95%', '95%', '96%', '96%', '96%', '96%', '96%']
  explained_variance_ratio: [ 0.59581138  0.2516909   0.02002546] ... [ 0.00123082  0.00119197  0.0011821 ] : sum = 0.954296810431
  vartotal ['60%', '85%', '87%', '88%', '89%', '90%', '90%', '91%', '91%', '92%', '92%', '92%', '93%', '93%', '93%', '93%', '94%', '94%', '94%', '94%', '94%', '94%', '95%', '95%', '95%', '95%', '95%', '95%', '95%', '95%']
  explained_variance_ratio: [ 0.59581138  0.2516909   0.02002546] ... [ 0.00190538  0.00176071  0.00172259] : sum = 0.940443856375
  vartotal ['60%', '85%', '87%', '88%', '89%', '90%', '90%', '91%', '91%', '92%', '92%', '92%', '93%', '93%', '93%', '93%', '94%', '94%', '94%', '94%']
  explained_variance_ratio: [ 0.59581138  0.2516909   0.02002546] ... [ 0.00479989  0.00434757  0.00393855] : sum = 0.917203731659
  vartotal ['60%', '85%', '87%', '88%', '89%', '90%', '90%', '91%', '91%', '92%']
fit shapes (7352, 562) (7352, 2) (2947, 562) (2947, 2)
raw data, all cols: svm fit score 0.99252, predict score 0.96709
classification report
             precision    recall  f1-score   support

          1       0.96      1.00      0.98       496
          2       0.97      0.96      0.97       471
          3       1.00      0.98      0.99       420
          4       0.97      0.89      0.93       491
          5       0.92      0.97      0.94       532
          6       1.00      1.00      1.00       537

avg / total       0.97      0.97      0.97      2947

confusion matrix
[[495   1   0   0   0   0]
 [ 19 452   0   0   0   0]
 [  2   6 412   0   0   0]
 [  0   5   0 436  48   2]
 [  1   0   0  13 518   0]
 [  0   0   0   0   0 537]]
fit shapes (7352, 30) (7352, 2) (2947, 30) (2947, 2)
raw data, 30 cols: svm fit score 0.72620, predict score 0.69528
classification report
             precision    recall  f1-score   support

          1       0.67      0.97      0.79       496
          2       0.90      0.56      0.69       471
          3       0.93      0.84      0.88       420
          4       0.51      0.18      0.27       491
          5       0.54      0.80      0.64       532
          6       0.75      0.82      0.78       537

avg / total       0.71      0.70      0.67      2947

confusion matrix
[[479  10   7   0   0   0]
 [188 262  21   0   0   0]
 [ 50  17 353   0   0   0]
 [  0   2   0  88 311  90]
 [  2   0   0  44 425  61]
 [  0   1   0  39  55 442]]
fit shapes (7352, 10) (7352, 2) (2947, 10) (2947, 2)
pca 10 cols: svm fit score 0.87854, predict score 0.85850
classification report
             precision    recall  f1-score   support

          1       0.85      0.97      0.91       496
          2       0.89      0.88      0.89       471
          3       0.89      0.79      0.83       420
          4       0.77      0.70      0.73       491
          5       0.75      0.81      0.78       532
          6       1.00      0.99      0.99       537

avg / total       0.86      0.86      0.86      2947

confusion matrix
[[479   0  17   0   0   0]
 [ 33 413  25   0   0   0]
 [ 47  43 330   0   0   0]
 [  0   5   0 343 142   1]
 [  2   1   0  96 433   0]
 [  0   0   0   5   0 532]]
fit shapes (7352, 20) (7352, 2) (2947, 20) (2947, 2)
pca 20 cols: svm fit score 0.91132, predict score 0.89175
classification report
             precision    recall  f1-score   support

          1       0.93      0.96      0.94       496
          2       0.90      0.93      0.91       471
          3       0.90      0.85      0.88       420
          4       0.82      0.76      0.79       491
          5       0.80      0.86      0.83       532
          6       1.00      0.98      0.99       537

avg / total       0.89      0.89      0.89      2947

confusion matrix
[[476   1  19   0   0   0]
 [ 15 436  19   0   1   0]
 [ 20  41 359   0   0   0]
 [  0   4   1 372 114   0]
 [  1   2   0  72 457   0]
 [  0   0   0   9   0 528]]
fit shapes (7352, 30) (7352, 2) (2947, 30) (2947, 2)
pca 30 cols: svm fit score 0.93158, predict score 0.91449
classification report
             precision    recall  f1-score   support

          1       0.89      0.96      0.93       496
          2       0.91      0.91      0.91       471
          3       0.93      0.86      0.90       420
          4       0.91      0.82      0.86       491
          5       0.85      0.92      0.88       532
          6       1.00      1.00      1.00       537

avg / total       0.92      0.91      0.91      2947

confusion matrix
[[475   5  16   0   0   0]
 [ 30 429  11   0   0   1]
 [ 24  33 363   0   0   0]
 [  0   2   0 403  86   0]
 [  2   1   0  41 488   0]
 [  0   0   0   0   0 537]]
fit shapes (7352, 50) (7352, 2) (2947, 50) (2947, 2)
pca 50 cols: svm fit score 0.96055, predict score 0.92942
classification report
             precision    recall  f1-score   support

          1       0.90      0.97      0.93       496
          2       0.94      0.86      0.90       471
          3       0.94      0.94      0.94       420
          4       0.94      0.85      0.89       491
          5       0.87      0.95      0.91       532
          6       1.00      1.00      1.00       537

avg / total       0.93      0.93      0.93      2947

confusion matrix
[[482   6   8   0   0   0]
 [ 47 407  17   0   0   0]
 [  6  20 394   0   0   0]
 [  0   1   0 416  74   0]
 [  1   0   0  28 503   0]
 [  0   0   0   0   0 537]]
fit shapes (7352, 100) (7352, 2) (2947, 100) (2947, 2)
pca 100 cols: svm fit score 0.98422, predict score 0.94978
classification report
             precision    recall  f1-score   support

          1       0.95      0.99      0.97       496
          2       0.96      0.94      0.95       471
          3       0.99      0.97      0.98       420
          4       0.95      0.84      0.89       491
          5       0.87      0.96      0.91       532
          6       0.99      1.00      1.00       537

avg / total       0.95      0.95      0.95      2947

confusion matrix
[[489   5   2   0   0   0]
 [ 23 443   3   0   0   2]
 [  3   8 408   0   0   1]
 [  0   5   0 412  73   1]
 [  0   0   0  22 510   0]
 [  0   0   0   0   0 537]]
preds [(10, 0.85850016966406517), (20, 0.89175432643366137), (30, 0.91448931116389554), (50, 0.9294197488971836), (100, 0.94977943671530374)]

Conclusion: Using PCA as input to LinearSVM is effective, with 91% accuracy using only
30 components (5.4% of 562 total).  For six predicted classes, a classification
report shows precision of 85% and greater (also confirmed by confusion matrix).

